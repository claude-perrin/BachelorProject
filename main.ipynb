{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /opt/homebrew/share/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/viktor/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /opt/homebrew/share/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/viktor/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/dataset\"\n",
    "\n",
    "role = \"arn:aws:iam::235411143540:role/SageMakerRole\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = sagemaker_session.upload_data(path=\"saved_dataset\", bucket=bucket, key_prefix=prefix)\n",
    "# print(\"input spec (in this case, just an S3 path): {}\".format(inputs))\n",
    "inputs = \"s3://sagemaker-eu-central-1-235411143540/saved_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01margparse\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mjson\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mlogging\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mos\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01msys\u001B[39;00m\n",
      "\n",
      "\u001B[38;2;61;123;123;03m#import sagemaker_containers\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mtorch\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mtorch\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01mdistributed\u001B[39;00m \u001B[38;2;0;128;0;01mas\u001B[39;00m \u001B[38;2;0;0;255;01mdist\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mtorch\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01mnn\u001B[39;00m \u001B[38;2;0;128;0;01mas\u001B[39;00m \u001B[38;2;0;0;255;01mnn\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mtorch\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01mnn\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01mfunctional\u001B[39;00m \u001B[38;2;0;128;0;01mas\u001B[39;00m \u001B[38;2;0;0;255;01mF\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mtorch\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01moptim\u001B[39;00m \u001B[38;2;0;128;0;01mas\u001B[39;00m \u001B[38;2;0;0;255;01moptim\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mtorch\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01mutils\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01mdata\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mimport\u001B[39;00m \u001B[38;2;0;0;255;01mtorch\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01mutils\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01mdata\u001B[39;00m\u001B[38;2;0;0;255;01m.\u001B[39;00m\u001B[38;2;0;0;255;01mdistributed\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mfrom\u001B[39;00m \u001B[38;2;0;0;255;01mtorchvision\u001B[39;00m \u001B[38;2;0;128;0;01mimport\u001B[39;00m datasets, transforms\n",
      "\n",
      "logger \u001B[38;2;102;102;102m=\u001B[39m logging\u001B[38;2;102;102;102m.\u001B[39mgetLogger(\u001B[38;2;25;23;124m__name__\u001B[39m)\n",
      "logger\u001B[38;2;102;102;102m.\u001B[39msetLevel(logging\u001B[38;2;102;102;102m.\u001B[39mDEBUG)\n",
      "logger\u001B[38;2;102;102;102m.\u001B[39maddHandler(logging\u001B[38;2;102;102;102m.\u001B[39mStreamHandler(sys\u001B[38;2;102;102;102m.\u001B[39mstdout))\n",
      "\n",
      "\n",
      "\u001B[38;2;61;123;123;03m# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\u001B[39;00m\n",
      "\u001B[38;2;0;128;0;01mclass\u001B[39;00m \u001B[38;2;0;0;255;01mNet\u001B[39;00m(nn\u001B[38;2;102;102;102m.\u001B[39mModule):\n",
      "    \u001B[38;2;0;128;0;01mdef\u001B[39;00m \u001B[38;2;0;0;255m__init__\u001B[39m(\u001B[38;2;0;128;0mself\u001B[39m):\n",
      "        \u001B[38;2;0;128;0msuper\u001B[39m(Net, \u001B[38;2;0;128;0mself\u001B[39m)\u001B[38;2;102;102;102m.\u001B[39m\u001B[38;2;0;0;255m__init__\u001B[39m()\n",
      "        \u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mconv1 \u001B[38;2;102;102;102m=\u001B[39m nn\u001B[38;2;102;102;102m.\u001B[39mConv2d(\u001B[38;2;102;102;102m1\u001B[39m, \u001B[38;2;102;102;102m10\u001B[39m, kernel_size\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m5\u001B[39m)\n",
      "        \u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mconv2 \u001B[38;2;102;102;102m=\u001B[39m nn\u001B[38;2;102;102;102m.\u001B[39mConv2d(\u001B[38;2;102;102;102m10\u001B[39m, \u001B[38;2;102;102;102m20\u001B[39m, kernel_size\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m5\u001B[39m)\n",
      "        \u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mconv2_drop \u001B[38;2;102;102;102m=\u001B[39m nn\u001B[38;2;102;102;102m.\u001B[39mDropout2d()\n",
      "        \u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mfc1 \u001B[38;2;102;102;102m=\u001B[39m nn\u001B[38;2;102;102;102m.\u001B[39mLinear(\u001B[38;2;102;102;102m320\u001B[39m, \u001B[38;2;102;102;102m50\u001B[39m)\n",
      "        \u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mfc2 \u001B[38;2;102;102;102m=\u001B[39m nn\u001B[38;2;102;102;102m.\u001B[39mLinear(\u001B[38;2;102;102;102m50\u001B[39m, \u001B[38;2;102;102;102m10\u001B[39m)\n",
      "\n",
      "    \u001B[38;2;0;128;0;01mdef\u001B[39;00m \u001B[38;2;0;0;255mforward\u001B[39m(\u001B[38;2;0;128;0mself\u001B[39m, x):\n",
      "        x \u001B[38;2;102;102;102m=\u001B[39m F\u001B[38;2;102;102;102m.\u001B[39mrelu(F\u001B[38;2;102;102;102m.\u001B[39mmax_pool2d(\u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mconv1(x), \u001B[38;2;102;102;102m2\u001B[39m))\n",
      "        x \u001B[38;2;102;102;102m=\u001B[39m F\u001B[38;2;102;102;102m.\u001B[39mrelu(F\u001B[38;2;102;102;102m.\u001B[39mmax_pool2d(\u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mconv2_drop(\u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mconv2(x)), \u001B[38;2;102;102;102m2\u001B[39m))\n",
      "        x \u001B[38;2;102;102;102m=\u001B[39m x\u001B[38;2;102;102;102m.\u001B[39mview(\u001B[38;2;102;102;102m-\u001B[39m\u001B[38;2;102;102;102m1\u001B[39m, \u001B[38;2;102;102;102m320\u001B[39m)\n",
      "        x \u001B[38;2;102;102;102m=\u001B[39m F\u001B[38;2;102;102;102m.\u001B[39mrelu(\u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mfc1(x))\n",
      "        x \u001B[38;2;102;102;102m=\u001B[39m F\u001B[38;2;102;102;102m.\u001B[39mdropout(x, training\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mtraining)\n",
      "        x \u001B[38;2;102;102;102m=\u001B[39m \u001B[38;2;0;128;0mself\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mfc2(x)\n",
      "        \u001B[38;2;0;128;0;01mreturn\u001B[39;00m F\u001B[38;2;102;102;102m.\u001B[39mlog_softmax(x, dim\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m1\u001B[39m)\n",
      "\n",
      "\n",
      "\u001B[38;2;0;128;0;01mdef\u001B[39;00m \u001B[38;2;0;0;255m_get_train_data_loader\u001B[39m(batch_size, training_dir, is_distributed, \u001B[38;2;102;102;102m*\u001B[39m\u001B[38;2;102;102;102m*\u001B[39mkwargs):\n",
      "    logger\u001B[38;2;102;102;102m.\u001B[39minfo(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mGet train data loader\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m)\n",
      "    dataset \u001B[38;2;102;102;102m=\u001B[39m datasets\u001B[38;2;102;102;102m.\u001B[39mMNIST(\n",
      "        training_dir,\n",
      "        train\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0;01mTrue\u001B[39;00m,\n",
      "        transform\u001B[38;2;102;102;102m=\u001B[39mtransforms\u001B[38;2;102;102;102m.\u001B[39mCompose(\n",
      "            [transforms\u001B[38;2;102;102;102m.\u001B[39mToTensor(), transforms\u001B[38;2;102;102;102m.\u001B[39mNormalize((\u001B[38;2;102;102;102m0.1307\u001B[39m,), (\u001B[38;2;102;102;102m0.3081\u001B[39m,))]\n",
      "        ),\n",
      "    )\n",
      "    train_sampler \u001B[38;2;102;102;102m=\u001B[39m (\n",
      "        torch\u001B[38;2;102;102;102m.\u001B[39mutils\u001B[38;2;102;102;102m.\u001B[39mdata\u001B[38;2;102;102;102m.\u001B[39mdistributed\u001B[38;2;102;102;102m.\u001B[39mDistributedSampler(dataset) \u001B[38;2;0;128;0;01mif\u001B[39;00m is_distributed \u001B[38;2;0;128;0;01melse\u001B[39;00m \u001B[38;2;0;128;0;01mNone\u001B[39;00m\n",
      "    )\n",
      "    \u001B[38;2;0;128;0;01mreturn\u001B[39;00m torch\u001B[38;2;102;102;102m.\u001B[39mutils\u001B[38;2;102;102;102m.\u001B[39mdata\u001B[38;2;102;102;102m.\u001B[39mDataLoader(\n",
      "        dataset,\n",
      "        batch_size\u001B[38;2;102;102;102m=\u001B[39mbatch_size,\n",
      "        shuffle\u001B[38;2;102;102;102m=\u001B[39mtrain_sampler \u001B[38;2;170;34;255;01mis\u001B[39;00m \u001B[38;2;0;128;0;01mNone\u001B[39;00m,\n",
      "        sampler\u001B[38;2;102;102;102m=\u001B[39mtrain_sampler,\n",
      "        \u001B[38;2;102;102;102m*\u001B[39m\u001B[38;2;102;102;102m*\u001B[39mkwargs\n",
      "    )\n",
      "\n",
      "\n",
      "\u001B[38;2;0;128;0;01mdef\u001B[39;00m \u001B[38;2;0;0;255m_get_test_data_loader\u001B[39m(test_batch_size, training_dir, \u001B[38;2;102;102;102m*\u001B[39m\u001B[38;2;102;102;102m*\u001B[39mkwargs):\n",
      "    logger\u001B[38;2;102;102;102m.\u001B[39minfo(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mGet test data loader\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m)\n",
      "    \u001B[38;2;0;128;0;01mreturn\u001B[39;00m torch\u001B[38;2;102;102;102m.\u001B[39mutils\u001B[38;2;102;102;102m.\u001B[39mdata\u001B[38;2;102;102;102m.\u001B[39mDataLoader(\n",
      "        datasets\u001B[38;2;102;102;102m.\u001B[39mMNIST(\n",
      "            training_dir,\n",
      "            train\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0;01mFalse\u001B[39;00m,\n",
      "            transform\u001B[38;2;102;102;102m=\u001B[39mtransforms\u001B[38;2;102;102;102m.\u001B[39mCompose(\n",
      "                [transforms\u001B[38;2;102;102;102m.\u001B[39mToTensor(), transforms\u001B[38;2;102;102;102m.\u001B[39mNormalize((\u001B[38;2;102;102;102m0.1307\u001B[39m,), (\u001B[38;2;102;102;102m0.3081\u001B[39m,))]\n",
      "            ),\n",
      "        ),\n",
      "        batch_size\u001B[38;2;102;102;102m=\u001B[39mtest_batch_size,\n",
      "        shuffle\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0;01mTrue\u001B[39;00m,\n",
      "        \u001B[38;2;102;102;102m*\u001B[39m\u001B[38;2;102;102;102m*\u001B[39mkwargs\n",
      "    )\n",
      "\n",
      "\n",
      "\u001B[38;2;0;128;0;01mdef\u001B[39;00m \u001B[38;2;0;0;255m_average_gradients\u001B[39m(model):\n",
      "    \u001B[38;2;61;123;123;03m# Gradient averaging.\u001B[39;00m\n",
      "    size \u001B[38;2;102;102;102m=\u001B[39m \u001B[38;2;0;128;0mfloat\u001B[39m(dist\u001B[38;2;102;102;102m.\u001B[39mget_world_size())\n",
      "    \u001B[38;2;0;128;0;01mfor\u001B[39;00m param \u001B[38;2;170;34;255;01min\u001B[39;00m model\u001B[38;2;102;102;102m.\u001B[39mparameters():\n",
      "        dist\u001B[38;2;102;102;102m.\u001B[39mall_reduce(param\u001B[38;2;102;102;102m.\u001B[39mgrad\u001B[38;2;102;102;102m.\u001B[39mdata, op\u001B[38;2;102;102;102m=\u001B[39mdist\u001B[38;2;102;102;102m.\u001B[39mreduce_op\u001B[38;2;102;102;102m.\u001B[39mSUM)\n",
      "        param\u001B[38;2;102;102;102m.\u001B[39mgrad\u001B[38;2;102;102;102m.\u001B[39mdata \u001B[38;2;102;102;102m/\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m size\n",
      "\n",
      "\n",
      "\u001B[38;2;0;128;0;01mdef\u001B[39;00m \u001B[38;2;0;0;255mtrain\u001B[39m(args):\n",
      "    is_distributed \u001B[38;2;102;102;102m=\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(args\u001B[38;2;102;102;102m.\u001B[39mhosts) \u001B[38;2;102;102;102m>\u001B[39m \u001B[38;2;102;102;102m1\u001B[39m \u001B[38;2;170;34;255;01mand\u001B[39;00m args\u001B[38;2;102;102;102m.\u001B[39mbackend \u001B[38;2;170;34;255;01mis\u001B[39;00m \u001B[38;2;170;34;255;01mnot\u001B[39;00m \u001B[38;2;0;128;0;01mNone\u001B[39;00m\n",
      "    logger\u001B[38;2;102;102;102m.\u001B[39mdebug(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mDistributed training - \u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mformat(is_distributed))\n",
      "    use_cuda \u001B[38;2;102;102;102m=\u001B[39m args\u001B[38;2;102;102;102m.\u001B[39mnum_gpus \u001B[38;2;102;102;102m>\u001B[39m \u001B[38;2;102;102;102m0\u001B[39m\n",
      "    logger\u001B[38;2;102;102;102m.\u001B[39mdebug(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mNumber of gpus available - \u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mformat(args\u001B[38;2;102;102;102m.\u001B[39mnum_gpus))\n",
      "    kwargs \u001B[38;2;102;102;102m=\u001B[39m {\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mnum_workers\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m: \u001B[38;2;102;102;102m1\u001B[39m, \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mpin_memory\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m: \u001B[38;2;0;128;0;01mTrue\u001B[39;00m} \u001B[38;2;0;128;0;01mif\u001B[39;00m use_cuda \u001B[38;2;0;128;0;01melse\u001B[39;00m {}\n",
      "    device \u001B[38;2;102;102;102m=\u001B[39m torch\u001B[38;2;102;102;102m.\u001B[39mdevice(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mcuda\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m \u001B[38;2;0;128;0;01mif\u001B[39;00m use_cuda \u001B[38;2;0;128;0;01melse\u001B[39;00m \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mcpu\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m)\n",
      "\n",
      "    \u001B[38;2;0;128;0;01mif\u001B[39;00m is_distributed:\n",
      "        \u001B[38;2;61;123;123;03m# Initialize the distributed environment.\u001B[39;00m\n",
      "        world_size \u001B[38;2;102;102;102m=\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(args\u001B[38;2;102;102;102m.\u001B[39mhosts)\n",
      "        os\u001B[38;2;102;102;102m.\u001B[39menviron[\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mWORLD_SIZE\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m] \u001B[38;2;102;102;102m=\u001B[39m \u001B[38;2;0;128;0mstr\u001B[39m(world_size)\n",
      "        host_rank \u001B[38;2;102;102;102m=\u001B[39m args\u001B[38;2;102;102;102m.\u001B[39mhosts\u001B[38;2;102;102;102m.\u001B[39mindex(args\u001B[38;2;102;102;102m.\u001B[39mcurrent_host)\n",
      "        os\u001B[38;2;102;102;102m.\u001B[39menviron[\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mRANK\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m] \u001B[38;2;102;102;102m=\u001B[39m \u001B[38;2;0;128;0mstr\u001B[39m(host_rank)\n",
      "        dist\u001B[38;2;102;102;102m.\u001B[39minit_process_group(backend\u001B[38;2;102;102;102m=\u001B[39margs\u001B[38;2;102;102;102m.\u001B[39mbackend, rank\u001B[38;2;102;102;102m=\u001B[39mhost_rank, world_size\u001B[38;2;102;102;102m=\u001B[39mworld_size)\n",
      "        logger\u001B[38;2;102;102;102m.\u001B[39minfo(\n",
      "            \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mInitialized the distributed environment: \u001B[39m\u001B[38;2;186;33;33m'\u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m'\u001B[39m\u001B[38;2;186;33;33m backend on \u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m nodes. \u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mformat(\n",
      "                args\u001B[38;2;102;102;102m.\u001B[39mbackend, dist\u001B[38;2;102;102;102m.\u001B[39mget_world_size()\n",
      "            )\n",
      "            \u001B[38;2;102;102;102m+\u001B[39m \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mCurrent host rank is \u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m. Number of gpus: \u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mformat(dist\u001B[38;2;102;102;102m.\u001B[39mget_rank(), args\u001B[38;2;102;102;102m.\u001B[39mnum_gpus)\n",
      "        )\n",
      "\n",
      "    \u001B[38;2;61;123;123;03m# set the seed for generating random numbers\u001B[39;00m\n",
      "    torch\u001B[38;2;102;102;102m.\u001B[39mmanual_seed(args\u001B[38;2;102;102;102m.\u001B[39mseed)\n",
      "    \u001B[38;2;0;128;0;01mif\u001B[39;00m use_cuda:\n",
      "        torch\u001B[38;2;102;102;102m.\u001B[39mcuda\u001B[38;2;102;102;102m.\u001B[39mmanual_seed(args\u001B[38;2;102;102;102m.\u001B[39mseed)\n",
      "\n",
      "    train_loader \u001B[38;2;102;102;102m=\u001B[39m _get_train_data_loader(args\u001B[38;2;102;102;102m.\u001B[39mbatch_size, args\u001B[38;2;102;102;102m.\u001B[39mdata_dir, is_distributed, \u001B[38;2;102;102;102m*\u001B[39m\u001B[38;2;102;102;102m*\u001B[39mkwargs)\n",
      "    test_loader \u001B[38;2;102;102;102m=\u001B[39m _get_test_data_loader(args\u001B[38;2;102;102;102m.\u001B[39mtest_batch_size, args\u001B[38;2;102;102;102m.\u001B[39mdata_dir, \u001B[38;2;102;102;102m*\u001B[39m\u001B[38;2;102;102;102m*\u001B[39mkwargs)\n",
      "\n",
      "    logger\u001B[38;2;102;102;102m.\u001B[39mdebug(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mProcesses \u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m/\u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m (\u001B[39m\u001B[38;2;164;90;119;01m{:.0f}\u001B[39;00m\u001B[38;2;186;33;33m%\u001B[39m\u001B[38;2;186;33;33m) of train data\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mformat(\n",
      "            \u001B[38;2;0;128;0mlen\u001B[39m(train_loader\u001B[38;2;102;102;102m.\u001B[39msampler),\n",
      "            \u001B[38;2;0;128;0mlen\u001B[39m(train_loader\u001B[38;2;102;102;102m.\u001B[39mdataset),\n",
      "            \u001B[38;2;102;102;102m100.0\u001B[39m \u001B[38;2;102;102;102m*\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(train_loader\u001B[38;2;102;102;102m.\u001B[39msampler) \u001B[38;2;102;102;102m/\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(train_loader\u001B[38;2;102;102;102m.\u001B[39mdataset),\n",
      "        )\n",
      "    )\n",
      "\n",
      "    logger\u001B[38;2;102;102;102m.\u001B[39mdebug(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mProcesses \u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m/\u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m (\u001B[39m\u001B[38;2;164;90;119;01m{:.0f}\u001B[39;00m\u001B[38;2;186;33;33m%\u001B[39m\u001B[38;2;186;33;33m) of test data\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mformat(\n",
      "            \u001B[38;2;0;128;0mlen\u001B[39m(test_loader\u001B[38;2;102;102;102m.\u001B[39msampler),\n",
      "            \u001B[38;2;0;128;0mlen\u001B[39m(test_loader\u001B[38;2;102;102;102m.\u001B[39mdataset),\n",
      "            \u001B[38;2;102;102;102m100.0\u001B[39m \u001B[38;2;102;102;102m*\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(test_loader\u001B[38;2;102;102;102m.\u001B[39msampler) \u001B[38;2;102;102;102m/\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(test_loader\u001B[38;2;102;102;102m.\u001B[39mdataset),\n",
      "        )\n",
      "    )\n",
      "\n",
      "    model \u001B[38;2;102;102;102m=\u001B[39m Net()\u001B[38;2;102;102;102m.\u001B[39mto(device)\n",
      "    \u001B[38;2;0;128;0;01mif\u001B[39;00m is_distributed \u001B[38;2;170;34;255;01mand\u001B[39;00m use_cuda:\n",
      "        \u001B[38;2;61;123;123;03m# multi-machine multi-gpu case\u001B[39;00m\n",
      "        model \u001B[38;2;102;102;102m=\u001B[39m torch\u001B[38;2;102;102;102m.\u001B[39mnn\u001B[38;2;102;102;102m.\u001B[39mparallel\u001B[38;2;102;102;102m.\u001B[39mDistributedDataParallel(model)\n",
      "    \u001B[38;2;0;128;0;01melse\u001B[39;00m:\n",
      "        \u001B[38;2;61;123;123;03m# single-machine multi-gpu case or single-machine or multi-machine cpu case\u001B[39;00m\n",
      "        model \u001B[38;2;102;102;102m=\u001B[39m torch\u001B[38;2;102;102;102m.\u001B[39mnn\u001B[38;2;102;102;102m.\u001B[39mDataParallel(model)\n",
      "\n",
      "    optimizer \u001B[38;2;102;102;102m=\u001B[39m optim\u001B[38;2;102;102;102m.\u001B[39mSGD(model\u001B[38;2;102;102;102m.\u001B[39mparameters(), lr\u001B[38;2;102;102;102m=\u001B[39margs\u001B[38;2;102;102;102m.\u001B[39mlr, momentum\u001B[38;2;102;102;102m=\u001B[39margs\u001B[38;2;102;102;102m.\u001B[39mmomentum)\n",
      "\n",
      "    \u001B[38;2;0;128;0;01mfor\u001B[39;00m epoch \u001B[38;2;170;34;255;01min\u001B[39;00m \u001B[38;2;0;128;0mrange\u001B[39m(\u001B[38;2;102;102;102m1\u001B[39m, args\u001B[38;2;102;102;102m.\u001B[39mepochs \u001B[38;2;102;102;102m+\u001B[39m \u001B[38;2;102;102;102m1\u001B[39m):\n",
      "        model\u001B[38;2;102;102;102m.\u001B[39mtrain()\n",
      "        \u001B[38;2;0;128;0;01mfor\u001B[39;00m batch_idx, (data, target) \u001B[38;2;170;34;255;01min\u001B[39;00m \u001B[38;2;0;128;0menumerate\u001B[39m(train_loader, \u001B[38;2;102;102;102m1\u001B[39m):\n",
      "            data, target \u001B[38;2;102;102;102m=\u001B[39m data\u001B[38;2;102;102;102m.\u001B[39mto(device), target\u001B[38;2;102;102;102m.\u001B[39mto(device)\n",
      "            optimizer\u001B[38;2;102;102;102m.\u001B[39mzero_grad()\n",
      "            output \u001B[38;2;102;102;102m=\u001B[39m model(data)\n",
      "            loss \u001B[38;2;102;102;102m=\u001B[39m F\u001B[38;2;102;102;102m.\u001B[39mnll_loss(output, target)\n",
      "            loss\u001B[38;2;102;102;102m.\u001B[39mbackward()\n",
      "            \u001B[38;2;0;128;0;01mif\u001B[39;00m is_distributed \u001B[38;2;170;34;255;01mand\u001B[39;00m \u001B[38;2;170;34;255;01mnot\u001B[39;00m use_cuda:\n",
      "                \u001B[38;2;61;123;123;03m# average gradients manually for multi-machine cpu case only\u001B[39;00m\n",
      "                _average_gradients(model)\n",
      "            optimizer\u001B[38;2;102;102;102m.\u001B[39mstep()\n",
      "            \u001B[38;2;0;128;0;01mif\u001B[39;00m batch_idx \u001B[38;2;102;102;102m%\u001B[39m args\u001B[38;2;102;102;102m.\u001B[39mlog_interval \u001B[38;2;102;102;102m==\u001B[39m \u001B[38;2;102;102;102m0\u001B[39m:\n",
      "                logger\u001B[38;2;102;102;102m.\u001B[39minfo(\n",
      "                    \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mTrain Epoch: \u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m [\u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m/\u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m (\u001B[39m\u001B[38;2;164;90;119;01m{:.0f}\u001B[39;00m\u001B[38;2;186;33;33m%\u001B[39m\u001B[38;2;186;33;33m)] Loss: \u001B[39m\u001B[38;2;164;90;119;01m{:.6f}\u001B[39;00m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mformat(\n",
      "                        epoch,\n",
      "                        batch_idx \u001B[38;2;102;102;102m*\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(data),\n",
      "                        \u001B[38;2;0;128;0mlen\u001B[39m(train_loader\u001B[38;2;102;102;102m.\u001B[39msampler),\n",
      "                        \u001B[38;2;102;102;102m100.0\u001B[39m \u001B[38;2;102;102;102m*\u001B[39m batch_idx \u001B[38;2;102;102;102m/\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(train_loader),\n",
      "                        loss\u001B[38;2;102;102;102m.\u001B[39mitem(),\n",
      "                    )\n",
      "                )\n",
      "        test(model, test_loader, device)\n",
      "    save_model(model, args\u001B[38;2;102;102;102m.\u001B[39mmodel_dir)\n",
      "\n",
      "\n",
      "\u001B[38;2;0;128;0;01mdef\u001B[39;00m \u001B[38;2;0;0;255mtest\u001B[39m(model, test_loader, device):\n",
      "    model\u001B[38;2;102;102;102m.\u001B[39meval()\n",
      "    test_loss \u001B[38;2;102;102;102m=\u001B[39m \u001B[38;2;102;102;102m0\u001B[39m\n",
      "    correct \u001B[38;2;102;102;102m=\u001B[39m \u001B[38;2;102;102;102m0\u001B[39m\n",
      "    \u001B[38;2;0;128;0;01mwith\u001B[39;00m torch\u001B[38;2;102;102;102m.\u001B[39mno_grad():\n",
      "        \u001B[38;2;0;128;0;01mfor\u001B[39;00m data, target \u001B[38;2;170;34;255;01min\u001B[39;00m test_loader:\n",
      "            data, target \u001B[38;2;102;102;102m=\u001B[39m data\u001B[38;2;102;102;102m.\u001B[39mto(device), target\u001B[38;2;102;102;102m.\u001B[39mto(device)\n",
      "            output \u001B[38;2;102;102;102m=\u001B[39m model(data)\n",
      "            test_loss \u001B[38;2;102;102;102m+\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m F\u001B[38;2;102;102;102m.\u001B[39mnll_loss(output, target, size_average\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0;01mFalse\u001B[39;00m)\u001B[38;2;102;102;102m.\u001B[39mitem()  \u001B[38;2;61;123;123;03m# sum up batch loss\u001B[39;00m\n",
      "            pred \u001B[38;2;102;102;102m=\u001B[39m output\u001B[38;2;102;102;102m.\u001B[39mmax(\u001B[38;2;102;102;102m1\u001B[39m, keepdim\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0;01mTrue\u001B[39;00m)[\u001B[38;2;102;102;102m1\u001B[39m]  \u001B[38;2;61;123;123;03m# get the index of the max log-probability\u001B[39;00m\n",
      "            correct \u001B[38;2;102;102;102m+\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m pred\u001B[38;2;102;102;102m.\u001B[39meq(target\u001B[38;2;102;102;102m.\u001B[39mview_as(pred))\u001B[38;2;102;102;102m.\u001B[39msum()\u001B[38;2;102;102;102m.\u001B[39mitem()\n",
      "\n",
      "    test_loss \u001B[38;2;102;102;102m/\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(test_loader\u001B[38;2;102;102;102m.\u001B[39mdataset)\n",
      "    logger\u001B[38;2;102;102;102m.\u001B[39minfo(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mTest set: Average loss: \u001B[39m\u001B[38;2;164;90;119;01m{:.4f}\u001B[39;00m\u001B[38;2;186;33;33m, Accuracy: \u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m/\u001B[39m\u001B[38;2;164;90;119;01m{}\u001B[39;00m\u001B[38;2;186;33;33m (\u001B[39m\u001B[38;2;164;90;119;01m{:.0f}\u001B[39;00m\u001B[38;2;186;33;33m%\u001B[39m\u001B[38;2;186;33;33m)\u001B[39m\u001B[38;2;170;93;31;01m\\n\u001B[39;00m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;102;102;102m.\u001B[39mformat(\n",
      "            test_loss, correct, \u001B[38;2;0;128;0mlen\u001B[39m(test_loader\u001B[38;2;102;102;102m.\u001B[39mdataset), \u001B[38;2;102;102;102m100.0\u001B[39m \u001B[38;2;102;102;102m*\u001B[39m correct \u001B[38;2;102;102;102m/\u001B[39m \u001B[38;2;0;128;0mlen\u001B[39m(test_loader\u001B[38;2;102;102;102m.\u001B[39mdataset)\n",
      "        )\n",
      "    )\n",
      "\n",
      "\n",
      "\u001B[38;2;0;128;0;01mdef\u001B[39;00m \u001B[38;2;0;0;255mmodel_fn\u001B[39m(model_dir):\n",
      "    device \u001B[38;2;102;102;102m=\u001B[39m torch\u001B[38;2;102;102;102m.\u001B[39mdevice(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mcuda\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m \u001B[38;2;0;128;0;01mif\u001B[39;00m torch\u001B[38;2;102;102;102m.\u001B[39mcuda\u001B[38;2;102;102;102m.\u001B[39mis_available() \u001B[38;2;0;128;0;01melse\u001B[39;00m \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mcpu\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m)\n",
      "    model \u001B[38;2;102;102;102m=\u001B[39m torch\u001B[38;2;102;102;102m.\u001B[39mnn\u001B[38;2;102;102;102m.\u001B[39mDataParallel(Net())\n",
      "    \u001B[38;2;0;128;0;01mwith\u001B[39;00m \u001B[38;2;0;128;0mopen\u001B[39m(os\u001B[38;2;102;102;102m.\u001B[39mpath\u001B[38;2;102;102;102m.\u001B[39mjoin(model_dir, \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mmodel.pth\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m), \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mrb\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m) \u001B[38;2;0;128;0;01mas\u001B[39;00m f:\n",
      "        model\u001B[38;2;102;102;102m.\u001B[39mload_state_dict(torch\u001B[38;2;102;102;102m.\u001B[39mload(f))\n",
      "    \u001B[38;2;0;128;0;01mreturn\u001B[39;00m model\u001B[38;2;102;102;102m.\u001B[39mto(device)\n",
      "\n",
      "\n",
      "\u001B[38;2;0;128;0;01mdef\u001B[39;00m \u001B[38;2;0;0;255msave_model\u001B[39m(model, model_dir):\n",
      "    logger\u001B[38;2;102;102;102m.\u001B[39minfo(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mSaving the model.\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m)\n",
      "    path \u001B[38;2;102;102;102m=\u001B[39m os\u001B[38;2;102;102;102m.\u001B[39mpath\u001B[38;2;102;102;102m.\u001B[39mjoin(model_dir, \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mmodel.pth\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m)\n",
      "    \u001B[38;2;61;123;123;03m# recommended way from http://pytorch.org/docs/master/notes/serialization.html\u001B[39;00m\n",
      "    torch\u001B[38;2;102;102;102m.\u001B[39msave(model\u001B[38;2;102;102;102m.\u001B[39mcpu()\u001B[38;2;102;102;102m.\u001B[39mstate_dict(), path)\n",
      "\n",
      "\n",
      "\u001B[38;2;0;128;0;01mif\u001B[39;00m \u001B[38;2;25;23;124m__name__\u001B[39m \u001B[38;2;102;102;102m==\u001B[39m \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m__main__\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m:\n",
      "    parser \u001B[38;2;102;102;102m=\u001B[39m argparse\u001B[38;2;102;102;102m.\u001B[39mArgumentParser()\n",
      "\n",
      "    \u001B[38;2;61;123;123;03m# Data and model checkpoints directories\u001B[39;00m\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--batch-size\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "        \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mint\u001B[39m,\n",
      "        default\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m64\u001B[39m,\n",
      "        metavar\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mN\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "        help\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33minput batch size for training (default: 64)\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "    )\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--test-batch-size\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "        \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mint\u001B[39m,\n",
      "        default\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m1000\u001B[39m,\n",
      "        metavar\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mN\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "        help\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33minput batch size for testing (default: 1000)\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "    )\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--epochs\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "        \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mint\u001B[39m,\n",
      "        default\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m10\u001B[39m,\n",
      "        metavar\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mN\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "        help\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mnumber of epochs to train (default: 10)\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "    )\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--lr\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mfloat\u001B[39m, default\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m0.01\u001B[39m, metavar\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mLR\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, help\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mlearning rate (default: 0.01)\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\n",
      "    )\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--momentum\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mfloat\u001B[39m, default\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m0.5\u001B[39m, metavar\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mM\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, help\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mSGD momentum (default: 0.5)\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\n",
      "    )\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--seed\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mint\u001B[39m, default\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m1\u001B[39m, metavar\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mS\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, help\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mrandom seed (default: 1)\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m)\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--log-interval\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "        \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mint\u001B[39m,\n",
      "        default\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;102;102;102m100\u001B[39m,\n",
      "        metavar\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mN\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "        help\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mhow many batches to wait before logging training status\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "    )\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\n",
      "        \u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--backend\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "        \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mstr\u001B[39m,\n",
      "        default\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0;01mNone\u001B[39;00m,\n",
      "        help\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mbackend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m,\n",
      "    )\n",
      "\n",
      "    \u001B[38;2;61;123;123;03m# Container environment\u001B[39;00m\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--hosts\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mlist\u001B[39m, default\u001B[38;2;102;102;102m=\u001B[39mjson\u001B[38;2;102;102;102m.\u001B[39mloads(os\u001B[38;2;102;102;102m.\u001B[39menviron[\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mSM_HOSTS\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m]))\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--current-host\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mstr\u001B[39m, default\u001B[38;2;102;102;102m=\u001B[39mos\u001B[38;2;102;102;102m.\u001B[39menviron[\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mSM_CURRENT_HOST\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m])\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--model-dir\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mstr\u001B[39m, default\u001B[38;2;102;102;102m=\u001B[39mos\u001B[38;2;102;102;102m.\u001B[39menviron[\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mSM_MODEL_DIR\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m])\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--data-dir\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mstr\u001B[39m, default\u001B[38;2;102;102;102m=\u001B[39mos\u001B[38;2;102;102;102m.\u001B[39menviron[\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mSM_CHANNEL_TRAINING\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m])\n",
      "    parser\u001B[38;2;102;102;102m.\u001B[39madd_argument(\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33m--num-gpus\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m, \u001B[38;2;0;128;0mtype\u001B[39m\u001B[38;2;102;102;102m=\u001B[39m\u001B[38;2;0;128;0mint\u001B[39m, default\u001B[38;2;102;102;102m=\u001B[39mos\u001B[38;2;102;102;102m.\u001B[39menviron[\u001B[38;2;186;33;33m\"\u001B[39m\u001B[38;2;186;33;33mSM_NUM_GPUS\u001B[39m\u001B[38;2;186;33;33m\"\u001B[39m])\n",
      "\n",
      "    train(parser\u001B[38;2;102;102;102m.\u001B[39mparse_args())\n"
     ]
    }
   ],
   "source": [
    "!pygmentize mnist.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /opt/homebrew/share/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/viktor/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"faster_rcnn.py\",\n",
    "    source_dir='src',        # Directory where your source code is located\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.11.0\",\n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.m4.xlarge\", # ml.c5.2xlarge\n",
    "    hyperparameters={\"epochs\": 10, \"backend\": \"gloo\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-10-29-18-45-08-711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-29 18:45:10 Starting - Starting the training job...\n",
      "2023-10-29 18:45:34 Starting - Preparing the instances for training......\n",
      "2023-10-29 18:46:38 Downloading - Downloading input data...............\n",
      "2023-10-29 18:49:14 Training - Downloading the training image...\n",
      "2023-10-29 18:49:34 Training - Training image download completed. Training in progress....\n",
      "2023-10-29 18:50:01 Uploading - Uploading generated training model\n",
      "2023-10-29 18:50:01 Failed - Training job failed\n",
      ".."
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2023-10-29-18-45-08-711: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"TypeError: 'type' object is not subscriptable\"\nCommand \"/opt/conda/bin/python3.8 faster_rcnn.py --backend gloo --epochs 10\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnexpectedStatusException\u001B[0m                 Traceback (most recent call last)",
      "\u001B[1;32m/Users/viktor/polsl/bachelor_project/sagemaker/main.ipynb Cell 5\u001B[0m line \u001B[0;36m1\n\u001B[0;32m----> <a href='vscode-notebook-cell:/Users/viktor/polsl/bachelor_project/sagemaker/main.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001B[0m estimator\u001B[39m.\u001B[39;49mfit({\u001B[39m\"\u001B[39;49m\u001B[39mtraining\u001B[39;49m\u001B[39m\"\u001B[39;49m: inputs})\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001B[0m, in \u001B[0;36mrunnable_by_pipeline.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    307\u001B[0m         \u001B[39mreturn\u001B[39;00m context\n\u001B[1;32m    309\u001B[0m     \u001B[39mreturn\u001B[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001B[39m*\u001B[39margs, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs)\n\u001B[0;32m--> 311\u001B[0m \u001B[39mreturn\u001B[39;00m run_func(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sagemaker/estimator.py:1315\u001B[0m, in \u001B[0;36mEstimatorBase.fit\u001B[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001B[0m\n\u001B[1;32m   1313\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mjobs\u001B[39m.\u001B[39mappend(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mlatest_training_job)\n\u001B[1;32m   1314\u001B[0m \u001B[39mif\u001B[39;00m wait:\n\u001B[0;32m-> 1315\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mlatest_training_job\u001B[39m.\u001B[39;49mwait(logs\u001B[39m=\u001B[39;49mlogs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sagemaker/estimator.py:2598\u001B[0m, in \u001B[0;36m_TrainingJob.wait\u001B[0;34m(self, logs)\u001B[0m\n\u001B[1;32m   2596\u001B[0m \u001B[39m# If logs are requested, call logs_for_jobs.\u001B[39;00m\n\u001B[1;32m   2597\u001B[0m \u001B[39mif\u001B[39;00m logs \u001B[39m!=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mNone\u001B[39m\u001B[39m\"\u001B[39m:\n\u001B[0;32m-> 2598\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49msagemaker_session\u001B[39m.\u001B[39;49mlogs_for_job(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mjob_name, wait\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m, log_type\u001B[39m=\u001B[39;49mlogs)\n\u001B[1;32m   2599\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m   2600\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39msagemaker_session\u001B[39m.\u001B[39mwait_for_job(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mjob_name)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sagemaker/session.py:4973\u001B[0m, in \u001B[0;36mSession.logs_for_job\u001B[0;34m(self, job_name, wait, poll, log_type, timeout)\u001B[0m\n\u001B[1;32m   4952\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mlogs_for_job\u001B[39m(\u001B[39mself\u001B[39m, job_name, wait\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m, poll\u001B[39m=\u001B[39m\u001B[39m10\u001B[39m, log_type\u001B[39m=\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mAll\u001B[39m\u001B[39m\"\u001B[39m, timeout\u001B[39m=\u001B[39m\u001B[39mNone\u001B[39;00m):\n\u001B[1;32m   4953\u001B[0m \u001B[39m    \u001B[39m\u001B[39m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001B[39;00m\n\u001B[1;32m   4954\u001B[0m \n\u001B[1;32m   4955\u001B[0m \u001B[39m    If the output is a tty or a Jupyter cell, it will be color-coded\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4971\u001B[0m \u001B[39m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001B[39;00m\n\u001B[1;32m   4972\u001B[0m \u001B[39m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4973\u001B[0m     _logs_for_job(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mboto_session, job_name, wait, poll, log_type, timeout)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sagemaker/session.py:6897\u001B[0m, in \u001B[0;36m_logs_for_job\u001B[0;34m(boto_session, job_name, wait, poll, log_type, timeout)\u001B[0m\n\u001B[1;32m   6894\u001B[0m             last_profiler_rule_statuses \u001B[39m=\u001B[39m profiler_rule_statuses\n\u001B[1;32m   6896\u001B[0m \u001B[39mif\u001B[39;00m wait:\n\u001B[0;32m-> 6897\u001B[0m     _check_job_status(job_name, description, \u001B[39m\"\u001B[39;49m\u001B[39mTrainingJobStatus\u001B[39;49m\u001B[39m\"\u001B[39;49m)\n\u001B[1;32m   6898\u001B[0m     \u001B[39mif\u001B[39;00m dot:\n\u001B[1;32m   6899\u001B[0m         \u001B[39mprint\u001B[39m()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sagemaker/session.py:6950\u001B[0m, in \u001B[0;36m_check_job_status\u001B[0;34m(job, desc, status_key_name)\u001B[0m\n\u001B[1;32m   6944\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39m\"\u001B[39m\u001B[39mCapacityError\u001B[39m\u001B[39m\"\u001B[39m \u001B[39min\u001B[39;00m \u001B[39mstr\u001B[39m(reason):\n\u001B[1;32m   6945\u001B[0m     \u001B[39mraise\u001B[39;00m exceptions\u001B[39m.\u001B[39mCapacityError(\n\u001B[1;32m   6946\u001B[0m         message\u001B[39m=\u001B[39mmessage,\n\u001B[1;32m   6947\u001B[0m         allowed_statuses\u001B[39m=\u001B[39m[\u001B[39m\"\u001B[39m\u001B[39mCompleted\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39m\"\u001B[39m\u001B[39mStopped\u001B[39m\u001B[39m\"\u001B[39m],\n\u001B[1;32m   6948\u001B[0m         actual_status\u001B[39m=\u001B[39mstatus,\n\u001B[1;32m   6949\u001B[0m     )\n\u001B[0;32m-> 6950\u001B[0m \u001B[39mraise\u001B[39;00m exceptions\u001B[39m.\u001B[39mUnexpectedStatusException(\n\u001B[1;32m   6951\u001B[0m     message\u001B[39m=\u001B[39mmessage,\n\u001B[1;32m   6952\u001B[0m     allowed_statuses\u001B[39m=\u001B[39m[\u001B[39m\"\u001B[39m\u001B[39mCompleted\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39m\"\u001B[39m\u001B[39mStopped\u001B[39m\u001B[39m\"\u001B[39m],\n\u001B[1;32m   6953\u001B[0m     actual_status\u001B[39m=\u001B[39mstatus,\n\u001B[1;32m   6954\u001B[0m )\n",
      "\u001B[0;31mUnexpectedStatusException\u001B[0m: Error for Training job pytorch-training-2023-10-29-18-45-08-711: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"TypeError: 'type' object is not subscriptable\"\nCommand \"/opt/conda/bin/python3.8 faster_rcnn.py --backend gloo --epochs 10\", exit code: 1"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": inputs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-eu-central-1-235411143540/pytorch-training-2023-10-27-19-14-02-631/output/model.tar.gz), script artifact (s3://sagemaker-eu-central-1-235411143540/pytorch-training-2023-10-27-19-14-02-631/source/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-eu-central-1-235411143540/pytorch-training-2023-10-27-19-49-51-655/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-training-2023-10-27-19-49-51-655\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-training-2023-10-27-19-49-51-655\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-training-2023-10-27-19-49-51-655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "data_dir = \"data/MNIST/raw\"\n",
    "with gzip.open(os.path.join(data_dir, \"t10k-images-idx3-ubyte.gz\"), \"rb\") as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28).astype(np.float32)\n",
    "\n",
    "mask = random.sample(range(len(images)), 16)  # randomly select some of the test images\n",
    "mask = np.array(mask, dtype=np.int32)\n",
    "data = images[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw prediction result:\n",
      "[[    0.         -1531.03552246  -775.55126953  -882.36639404\n",
      "  -1270.45324707  -764.815979    -803.70916748 -1069.17114258\n",
      "   -846.71520996 -1144.79272461]\n",
      " [ -355.86022949  -440.81268311  -202.45556641  -266.35440063\n",
      "   -401.78820801  -287.02746582  -264.79299927  -576.97924805\n",
      "      0.          -450.95666504]\n",
      " [ -800.54821777  -702.08032227  -719.37127686  -437.40423584\n",
      "    -19.32922363  -343.06335449  -536.19616699  -357.53234863\n",
      "   -276.92120361     0.        ]\n",
      " [ -645.06445312  -817.94506836  -521.99169922  -694.60449219\n",
      "      0.          -513.83740234  -381.3157959   -398.30310059\n",
      "   -555.9921875   -121.46380615]\n",
      " [ -357.71896362  -962.51599121 -1015.74230957  -680.15093994\n",
      "   -666.33557129     0.          -534.38995361  -856.23693848\n",
      "   -422.42626953  -573.88012695]\n",
      " [ -819.02593994 -1104.11669922  -689.6842041  -1209.65405273\n",
      "   -659.09802246  -546.53356934     0.         -1378.28796387\n",
      "   -805.45489502 -1012.93432617]\n",
      " [ -484.87252808  -614.40661621  -453.84750366  -701.50537109\n",
      "    -93.70651245  -325.65887451     0.          -732.47674561\n",
      "   -498.28503418  -366.34851074]\n",
      " [ -864.89367676  -563.41149902  -569.86663818     0.\n",
      "  -1001.46813965  -456.31408691  -927.51104736  -788.0723877\n",
      "   -554.10241699  -804.78619385]\n",
      " [ -218.83981323  -355.72155762     0.          -332.71469116\n",
      "   -321.63140869  -390.01821899  -124.10774231  -432.21386719\n",
      "   -195.24407959  -392.17584229]\n",
      " [ -641.00421143  -104.61210632  -388.60668945  -253.2147522\n",
      "   -287.53543091  -302.73629761  -583.36999512     0.\n",
      "    -24.7250824    -31.34117126]\n",
      " [ -783.61767578     0.          -288.21511841  -504.97497559\n",
      "   -528.53430176  -625.63964844  -542.39672852  -543.38818359\n",
      "   -302.31768799  -580.06860352]\n",
      " [ -821.30474854  -670.8548584   -562.62127686  -288.82348633\n",
      "   -163.99331665  -445.56707764  -641.06140137  -225.40892029\n",
      "   -390.40707397     0.        ]\n",
      " [ -882.57043457  -993.15258789  -746.38568115  -802.28155518\n",
      "      0.          -736.19134521  -638.42144775  -594.53948975\n",
      "   -628.91894531  -274.07662964]\n",
      " [ -347.95822144  -978.96801758  -751.68457031  -612.77264404\n",
      "   -616.88000488     0.          -203.94094849  -927.66607666\n",
      "   -529.12774658  -632.15087891]\n",
      " [-1017.86151123     0.          -572.97351074  -565.74188232\n",
      "   -566.73834229  -673.61761475  -687.50708008  -547.92102051\n",
      "   -563.53790283  -585.07092285]\n",
      " [-1166.64440918 -1218.38293457 -1108.50622559 -1145.75036621\n",
      "      0.          -847.92321777  -759.57318115  -737.06713867\n",
      "   -776.37811279  -323.097229  ]]\n",
      "\n",
      "Labeled predictions: \n",
      "[(0, 0.0), (1, -1531.0355224609375), (2, -775.55126953125), (3, -882.3663940429688), (4, -1270.4532470703125), (5, -764.8159790039062), (6, -803.7091674804688), (7, -1069.171142578125), (8, -846.7152099609375), (9, -1144.792724609375)]\n",
      "\n",
      "Most likely answer: (0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "response = predictor.predict(np.expand_dims(data, axis=1))\n",
    "print(\"Raw prediction result:\")\n",
    "print(response)\n",
    "print()\n",
    "\n",
    "labeled_predictions = list(zip(range(10), response[0]))\n",
    "print(\"Labeled predictions: \")\n",
    "print(labeled_predictions)\n",
    "print()\n",
    "\n",
    "labeled_predictions.sort(key=lambda label_and_prob: 1.0 - label_and_prob[1])\n",
    "print(\"Most likely answer: {}\".format(labeled_predictions[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: pytorch-training-2023-10-27-19-49-51-655\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"pytorch-training-2023-10-27-19-49-51-655\".",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m/Users/viktor/polsl/bachelor_project/sagemaker/main.ipynb Cell 10\u001B[0m line \u001B[0;36m1\n\u001B[0;32m----> <a href='vscode-notebook-cell:/Users/viktor/polsl/bachelor_project/sagemaker/main.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001B[0m sagemaker_session\u001B[39m.\u001B[39;49mdelete_endpoint(endpoint_name\u001B[39m=\u001B[39;49mpredictor\u001B[39m.\u001B[39;49mendpoint_name)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sagemaker/session.py:4238\u001B[0m, in \u001B[0;36mSession.delete_endpoint\u001B[0;34m(self, endpoint_name)\u001B[0m\n\u001B[1;32m   4232\u001B[0m \u001B[39m\u001B[39m\u001B[39m\"\"\"Delete an Amazon SageMaker ``Endpoint``.\u001B[39;00m\n\u001B[1;32m   4233\u001B[0m \n\u001B[1;32m   4234\u001B[0m \u001B[39mArgs:\u001B[39;00m\n\u001B[1;32m   4235\u001B[0m \u001B[39m    endpoint_name (str): Name of the Amazon SageMaker ``Endpoint`` to delete.\u001B[39;00m\n\u001B[1;32m   4236\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m   4237\u001B[0m LOGGER\u001B[39m.\u001B[39minfo(\u001B[39m\"\u001B[39m\u001B[39mDeleting endpoint with name: \u001B[39m\u001B[39m%s\u001B[39;00m\u001B[39m\"\u001B[39m, endpoint_name)\n\u001B[0;32m-> 4238\u001B[0m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49msagemaker_client\u001B[39m.\u001B[39;49mdelete_endpoint(EndpointName\u001B[39m=\u001B[39;49mendpoint_name)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/botocore/client.py:535\u001B[0m, in \u001B[0;36mClientCreator._create_api_method.<locals>._api_call\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    531\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mTypeError\u001B[39;00m(\n\u001B[1;32m    532\u001B[0m         \u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m{\u001B[39;00mpy_operation_name\u001B[39m}\u001B[39;00m\u001B[39m() only accepts keyword arguments.\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m    533\u001B[0m     )\n\u001B[1;32m    534\u001B[0m \u001B[39m# The \"self\" in this scope is referring to the BaseClient.\u001B[39;00m\n\u001B[0;32m--> 535\u001B[0m \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/botocore/client.py:980\u001B[0m, in \u001B[0;36mBaseClient._make_api_call\u001B[0;34m(self, operation_name, api_params)\u001B[0m\n\u001B[1;32m    978\u001B[0m     error_code \u001B[39m=\u001B[39m parsed_response\u001B[39m.\u001B[39mget(\u001B[39m\"\u001B[39m\u001B[39mError\u001B[39m\u001B[39m\"\u001B[39m, {})\u001B[39m.\u001B[39mget(\u001B[39m\"\u001B[39m\u001B[39mCode\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[1;32m    979\u001B[0m     error_class \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mexceptions\u001B[39m.\u001B[39mfrom_code(error_code)\n\u001B[0;32m--> 980\u001B[0m     \u001B[39mraise\u001B[39;00m error_class(parsed_response, operation_name)\n\u001B[1;32m    981\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    982\u001B[0m     \u001B[39mreturn\u001B[39;00m parsed_response\n",
      "\u001B[0;31mClientError\u001B[0m: An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"pytorch-training-2023-10-27-19-49-51-655\"."
     ]
    }
   ],
   "source": [
    "sagemaker_session.delete_endpoint(endpoint_name=predictor.endpoint_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
