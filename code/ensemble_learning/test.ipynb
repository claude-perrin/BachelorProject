{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "from torchvision.ops.boxes import box_convert,box_iou\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2 \n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn \n",
    "from torchvision.models.detection import ssd300_vgg16, SSD300_VGG16_Weights, ssd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "torch.manual_seed = 0\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from conf import *\n",
    "from inference.inference_helper import preprocess_image, inference_filter_prediction,denormalize_polygon\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "\n",
    "model_path1 = \"../models/Good_FasterRcnn_V1_epoch-6_model.pth\"\n",
    "model_path2 = \"../models/Good_FasterRcnn_V2_epoch-4_model.pth\"\n",
    "model_path3 = \"../models/Good_SSD_epoch-8_model.pth\"\n",
    "yolo_path4 = \"../models/yolov8.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model1(num_classes=NUMBER_OF_CLASSES):\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    state_dict= torch.load(model_path1)\n",
    "    updated_state = {k.replace(\"module.\", \"\"): v for k,v in state_dict.items()}\n",
    "    model.load_state_dict(updated_state)\n",
    "    print(f\"MODEL from volume: {model_path1} is loaded successfuly\")\n",
    "    return model\n",
    "\n",
    "def load_model2(num_classes=NUMBER_OF_CLASSES):\n",
    "    model = fasterrcnn_resnet50_fpn_v2(pretrained=False)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    state_dict= torch.load(model_path2)\n",
    "    updated_state = {k.replace(\"module.\", \"\"): v for k,v in state_dict.items()}\n",
    "    model.load_state_dict(updated_state)\n",
    "    print(f\"MODEL from volume: {model_path2} is loaded successfuly\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ssd_detection_model(num_classes=NUMBER_OF_CLASSES):\n",
    "    ssd_model = ssd300_vgg16(weights=False)\n",
    "    num_anchors = ssd_model.anchor_generator.num_anchors_per_location()\n",
    "    out_channels = [512,1024,512,256,256,256]\n",
    "    ssd_model.head = ssd.SSDHead(out_channels, num_anchors, num_classes+1)\n",
    "    state_dict= torch.load(model_path3)\n",
    "    updated_state = {k.replace(\"module.\", \"\"): v for k,v in state_dict.items()}\n",
    "    ssd_model.load_state_dict(updated_state)\n",
    "    print(f\"MODEL from volume: {model_path3} is loaded successfuly\")\n",
    "\n",
    "    return ssd_model\n",
    "\n",
    "def load_yolo():\n",
    "    model = YOLO(yolo_path4)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def save_test_img(img, target, prefix):\n",
    "    # img = img.permute(2,0,1).cpu().numpy()  # Convert to (height, width, channels)\n",
    "    img = img.cpu().numpy()  # Convert to (height, width, channels)\n",
    "\n",
    "    # img = img.astype('uint8')\n",
    "    # img = img\n",
    "    # Draw bounding boxes on the image\n",
    "    print(target)\n",
    "    for box, label in zip(target['boxes'], target['labels']):\n",
    "        x, y, w, h = box.tolist()\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        # box_color = BOX_COLOR[label.item()]\n",
    "        print(label)\n",
    "        box_color = (255,255,255)\n",
    "        cv2.rectangle(img, (x, y), (w, h), box_color, 2)\n",
    "\n",
    "    # Save the image with bounding boxes\n",
    "    if not os.path.exists(os.path.join(os.getcwd(), 'test_output')):\n",
    "        os.makedirs(os.path.join(os.getcwd(), 'test_output'))\n",
    "    # cv2.imshow(img)\n",
    "    img_path = f\"./test_output/output_image_{prefix}.png\"\n",
    "    cv2.imwrite(img_path, img)\n",
    "    return img_path\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader, 1):\n",
    "        data = list(image.to(device) for image in data)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, targets)\n",
    "        print(f\"=====[ epoch {epoch} batch {batch_idx}  output of the model: {output}\")\n",
    "\n",
    "        loss = output[\"loss_classifier\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def run(model, train_loader):\n",
    "    epochs = 2\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, train_loader, optimizer, epoch)\n",
    "        scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = load_model1()\n",
    "# model2 = load_model2()\n",
    "# model3 = get_ssd_detection_model()\n",
    "model4 = load_yolo()\n",
    "\n",
    "# model1.eval()\n",
    "# model2.eval()\n",
    "# model3.eval()\n",
    "# model4.eval()\n",
    "\n",
    "original_image_sizes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x1280 4 vehicles, 190.6ms\n",
      "Speed: 0.0ms preprocess, 190.6ms inference, 3.9ms postprocess per image at shape (1, 3, 960, 1280)\n",
      "Model4 filtering: \n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([4., 4., 4., 4.])\n",
      "conf: tensor([0.3592, 0.3114, 0.2985, 0.2932])\n",
      "data: tensor([[2.4553e+02, 2.8972e+02, 2.7939e+02, 3.1989e+02, 3.5917e-01, 4.0000e+00],\n",
      "        [1.3890e+02, 3.2939e+01, 2.4867e+02, 9.6170e+01, 3.1142e-01, 4.0000e+00],\n",
      "        [3.2268e+02, 1.7719e+02, 3.5399e+02, 2.1675e+02, 2.9854e-01, 4.0000e+00],\n",
      "        [2.6119e+02, 3.2223e+02, 2.9206e+02, 3.4298e+02, 2.9323e-01, 4.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (960, 1280)\n",
      "shape: torch.Size([4, 6])\n",
      "xywh: tensor([[262.4594, 304.8049,  33.8540,  30.1717],\n",
      "        [193.7836,  64.5543, 109.7757,  63.2313],\n",
      "        [338.3377, 196.9695,  31.3095,  39.5687],\n",
      "        [276.6281, 332.6047,  30.8663,  20.7512]])\n",
      "xywhn: tensor([[0.2050, 0.3175, 0.0264, 0.0314],\n",
      "        [0.1514, 0.0672, 0.0858, 0.0659],\n",
      "        [0.2643, 0.2052, 0.0245, 0.0412],\n",
      "        [0.2161, 0.3465, 0.0241, 0.0216]])\n",
      "xyxy: tensor([[245.5323, 289.7191, 279.3864, 319.8908],\n",
      "        [138.8958,  32.9386, 248.6715,  96.1699],\n",
      "        [322.6829, 177.1852, 353.9924, 216.7538],\n",
      "        [261.1950, 322.2291, 292.0613, 342.9803]])\n",
      "xyxyn: tensor([[0.1918, 0.3018, 0.2183, 0.3332],\n",
      "        [0.1085, 0.0343, 0.1943, 0.1002],\n",
      "        [0.2521, 0.1846, 0.2766, 0.2258],\n",
      "        [0.2041, 0.3357, 0.2282, 0.3573]])\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"./real_images/complex.jpg\"\n",
    "image_dim = (960,1280)\n",
    "denormalized_road_roi_polygon = denormalize_polygon(image_dim, ROAD_ROI_POLYGON)\n",
    "\n",
    "image = cv2.imread(image_dir)\n",
    "grayscale = preprocess_image(image)\n",
    "# grayscale = grayscale.unsqueeze(0)\n",
    "inputs = grayscale\n",
    "inputs = inputs.permute(0,3,2,1)\n",
    "\n",
    "# timer_model1 = datetime.datetime.now()\n",
    "# outputs1 = model1(inputs)\n",
    "# timer_model1 = datetime.datetime.now() - timer_model1 \n",
    "\n",
    "# # print(f\"outputs1: {outputs1}\")\n",
    "# timer_model2 = datetime.datetime.now()\n",
    "# outputs2 = model2(inputs)\n",
    "# timer_model2 = datetime.datetime.now() - timer_model2\n",
    "\n",
    "# timer_model3 = datetime.datetime.now()\n",
    "# outputs3 = model3(inputs)\n",
    "# timer_model3 = datetime.datetime.now() - timer_model3\n",
    "\n",
    "timer_model4 = datetime.datetime.now()\n",
    "outputs4 = model4(inputs)\n",
    "timer_model4 = datetime.datetime.now() - timer_model4\n",
    "\n",
    "# print(f\"outputs1: {outputs1}\")\n",
    "# print(\"Model1 filtering: \")\n",
    "# outputs1 = inference_filter_prediction(outputs1)\n",
    "# print(\"Model2 filtering: \")\n",
    "# outputs2 = inference_filter_prediction(outputs2)\n",
    "# print(\"Model3 filtering: \")\n",
    "# outputs3 = inference_filter_prediction(outputs3)\n",
    "print(\"Model4 filtering: \")\n",
    "# outputs4 = inference_filter_prediction(outputs4, normalized_road_roi_polygon=denormalized_road_roi_polygon)\n",
    "# print(outputs4)\n",
    "# print(f\"Time\\nModel1 (Rcnn_V1): {timer_model1}\\nModel2 (Rcnn_V2): {timer_model2}\\nModel3 (SSD): {timer_model3}\")\n",
    "# Display the results\n",
    "# outputs4.show()\n",
    "for r in outputs4:\n",
    "    print(r.boxes)\n",
    "\n",
    "# Save the results (optional)\n",
    "\n",
    "# it = random.randint(0, 1000)\n",
    "# prefix=f\"detections-{it}\"\n",
    "# print(prefix)\n",
    "# print(outputs3)\n",
    "\n",
    "# for output1, output2, output3 in zip(outputs1, outputs2,outputs3):\n",
    "#     save_test_img(torch.clone(image), output1, f\"model1_{prefix}\")\n",
    "#     save_test_img(torch.clone(image), output2, f\"model2_{prefix}\")\n",
    "#     save_test_img(image, output3, f\"model3_{prefix}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
